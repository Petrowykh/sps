import pandas as pd
import requests
import streamlit as st
from api import post_json, PARAMS, HEADERS
from pathlib import Path
import datetime
import time
import logging
import threading
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FutureTimeoutError

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TimeoutException(Exception):
    pass

def timeout_handler():
    raise TimeoutException("–¢–∞–π–º–∞—É—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏")

def run_with_timeout(func, timeout_seconds, *args, **kwargs):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é —Å —Ç–∞–π–º–∞—É—Ç–æ–º"""
    with ThreadPoolExecutor(max_workers=1) as executor:
        future = executor.submit(func, *args, **kwargs)
        try:
            return future.result(timeout=timeout_seconds)
        except FutureTimeoutError:
            raise TimeoutException(f"–¢–∞–π–º–∞—É—Ç –ø–æ—Å–ª–µ {timeout_seconds} —Å–µ–∫—É–Ω–¥")

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è —Å–µ—Å—Å–∏—è —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
def create_session():
    """–°–æ–∑–¥–∞–µ—Ç —Å–µ—Å—Å–∏—é —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –∏ —Ç–∞–π–º–∞—É—Ç–∞–º–∏"""
    session = requests.Session()
    
    from requests.adapters import HTTPAdapter
    from urllib3.util.retry import Retry
    
    retry_strategy = Retry(
        total=2,
        backoff_factor=1,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["POST"]
    )
    
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    
    return session

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é —Å–µ—Å—Å–∏—é
SESSION = create_session()

def get_main_group():
    try:
        data_group = '{"CRC":"","Packet":{"FromId":"10003001","ServerKey":"omt5W465fjwlrtxcEco97kew2dkdrorqqq","Data":{}}}'
        response = SESSION.post('https://api.infoprice.by/InfoPrice.GoodsGroup', params=PARAMS, headers=HEADERS, data=data_group, timeout=30)
        response.raise_for_status()
        main_group = response.json()
        return {i['GoodsGroupName']: [i['GoodsGroupId'], i['Child']] for i in main_group['Table']}
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –≥–ª–∞–≤–Ω—ã—Ö –≥—Ä—É–ø–ø: {e}")
        return {}

def create_data_group(group_id, page="", is_promo=False):
    promo_flag = 1 if is_promo else 0
    data = f'{{"CRC":"","Packet":{{"FromId":"10003001","ServerKey":"omt5W465fjwlrtxcEco97kew2dkdrorqqq","Data":{{"ContractorId":"","GoodsGroupId":"{group_id}","Page":"{page}","Search":"","OrderBy":0,"OrderByContractor":0,"Compare–°ontractorId":72631,"CatalogType":1,"IsAgeLimit":0,"IsPromotionalPrice":{promo_flag}}}}}}}'
    return data.encode()

def get_price_group(group_id, page, is_promo=False):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≥—Ä—É–ø–ø—ã —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    max_retries = 2
    base_timeout = 45
    
    for attempt in range(max_retries):
        try:
            data = create_data_group(group_id, page=page, is_promo=is_promo)
            timeout = base_timeout * (attempt + 1)
            
            response = SESSION.post(
                'https://api.infoprice.by/InfoPrice.Goods', 
                params=PARAMS, 
                headers=HEADERS, 
                data=data,
                timeout=timeout
            )
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.Timeout:
            if attempt == max_retries - 1:
                st.error(f"–¢–∞–π–º–∞—É—Ç –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –≥—Ä—É–ø–ø—ã {group_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page}")
                raise
            else:
                wait_time = 3 * (attempt + 1)
                st.warning(f"–¢–∞–π–º–∞—É—Ç –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}. –ñ–¥–µ–º {wait_time} —Å–µ–∫...")
                time.sleep(wait_time)
                
        except requests.exceptions.ConnectionError:
            if attempt == max_retries - 1:
                st.error(f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –≥—Ä—É–ø–ø—ã {group_id}")
                raise
            else:
                wait_time = 5 * (attempt + 1)
                st.warning(f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}. –ñ–¥–µ–º {wait_time} —Å–µ–∫...")
                time.sleep(wait_time)
                
        except Exception as e:
            if attempt == max_retries - 1:
                st.error(f"–û—à–∏–±–∫–∞ –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –≥—Ä—É–ø–ø—ã {group_id}: {e}")
                raise
            else:
                wait_time = 2 * (attempt + 1)
                st.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}. –ñ–¥–µ–º {wait_time} —Å–µ–∫...")
                time.sleep(wait_time)
    
    return None

def process_goods(goods, main_name, is_promo=False):
    processed_data = []
    
    if 'GoodsOffer' not in goods or not goods['GoodsOffer']:
        return processed_data
        
    for data_good in goods['GoodsOffer']:
        goods_group_name = data_good.get('GoodsGroupName', '')
        goods_name = data_good.get('GoodsName', '').rstrip()
        goods_id = data_good.get('GoodsId', '')
        
        if not goods_id:
            continue
            
        prices = {72494: 0.00, 72512: 0.00, 72511: 0.00, 72517: 0.00, 72468: 0.00, 72526: 0.00}
        has_any_price = False
        has_promo_price = False
        
        if 'Offers' in data_good and data_good['Offers']:
            for price_contractor in data_good['Offers']:
                contractor_id = price_contractor.get('ContractorId')
                if contractor_id in prices:
                    price_value = float(price_contractor.get('Price', 0))
                    is_promo_price = price_contractor.get('IsPromotionalPrice', False)
                    
                    if not is_promo:
                        # –î–ª—è –æ–±—ã—á–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ - –±–µ—Ä–µ–º –≤—Å–µ —Ü–µ–Ω—ã
                        prices[contractor_id] = price_value
                        if price_value > 0:
                            has_any_price = True
                    else:
                        # –î–ª—è –ø—Ä–æ–º–æ-–∑–∞–ø—Ä–æ—Å–∞ - –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ–º–æ-—Ü–µ–Ω—ã
                        if is_promo_price:
                            prices[contractor_id] = price_value
                            has_promo_price = True
        
        # –î–ª—è –æ–±—ã—á–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞: –¥–æ–±–∞–≤–ª—è–µ–º –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞ —Ü–µ–Ω–∞
        if not is_promo:
            if not has_any_price:
                continue
        # –î–ª—è –ø—Ä–æ–º–æ-—Ä–µ–∂–∏–º–∞: –¥–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–º–æ-—Ü–µ–Ω—ã
        else:
            if not has_promo_price:
                continue
        
        link = 'https://infoprice.by/?search=' + "+".join(goods_name.split(" "))
        
        if is_promo:
            processed_data.append((goods_id, *prices.values()))
        else:
            processed_data.append((goods_id, main_name, goods_group_name, goods_name, link, *prices.values()))
    
    return processed_data

def safe_get_pages_count(data):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü"""
    try:
        if data and 'Table' in data and data['Table']:
            general_data = data['Table'][0].get('GeneralData', [{}])[0]
            return general_data.get('AmountPages', 0)
    except (IndexError, KeyError, TypeError):
        pass
    return 0

def safe_get_goods_data(data):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–≤–∞—Ä–∞—Ö"""
    try:
        if data and 'Table' in data and data['Table']:
            for goods in data['Table']:
                general_data = goods.get('GeneralData', [{}])[0]
                amount_goods = general_data.get('AmountGoods', 0)
                if amount_goods > 0 and 'GoodsOffer' in goods:
                    yield goods
    except (IndexError, KeyError, TypeError):
        pass

def _store_row(row: tuple, cols: list, dd: dict) -> None:
    gid = row[0]
    if gid not in dd:
        dd[gid] = {c: 0.0 for c in cols}
        dd[gid]["good_id"], dd[gid]["category"], dd[gid]["subcategory"], dd[gid]["name"], dd[gid]["link"] = row[:5]
    for idx, col in enumerate(cols[5:11], start=5):
        dd[gid][col] = row[idx]

def _store_promo(row: tuple, cols: list, dd: dict) -> None:
    gid = row[0]
    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–º–æ-—Ü–µ–Ω—ã –¢–û–õ–¨–ö–û –µ—Å–ª–∏ —Ç–æ–≤–∞—Ä —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    if gid in dd:
        for idx, col in enumerate(cols[11:], start=1):
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø—Ä–æ–º–æ-—Ü–µ–Ω–∞ –Ω–µ –Ω—É–ª–µ–≤–∞—è
            if row[idx] > 0:
                dd[gid][col] = row[idx]

def safe_process_group(gid, gname, main_name, data_dict, columns):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥—Ä—É–ø–ø—ã —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –∑–∞–≤–∏—Å–∞–Ω–∏–π"""
    
    def process_single_group(group_id, group_name, is_promo=False):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –≥—Ä—É–ø–ø—ã (–æ–±—ã—á–Ω—ã–µ –∏–ª–∏ –ø—Ä–æ–º–æ —Ü–µ–Ω—ã)"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –æ–±—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å —Ç–∞–π–º–∞—É—Ç–æ–º
            general_data = run_with_timeout(
                get_price_group, 120, group_id, "", is_promo
            )
            
            if not general_data:
                return 0
                
            pages_count = safe_get_pages_count(general_data)
            if pages_count == 0:
                return 0
            
            processed_goods = 0
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º–∏ —Ç–∞–π–º–∞—É—Ç–∞–º–∏
            for page in range(pages_count):
                try:
                    page_data = run_with_timeout(
                        get_price_group, 180, group_id, str(page), is_promo
                    )
                    
                    if page_data:
                        for goods in safe_get_goods_data(page_data):
                            rows = process_goods(goods, main_name, is_promo)
                            for row in rows:
                                if is_promo:
                                    # –î–ª—è –ø—Ä–æ–º–æ-—Ü–µ–Ω –¥–æ–±–∞–≤–ª—è–µ–º –¢–û–õ–¨–ö–û –µ—Å–ª–∏ —Ç–æ–≤–∞—Ä —É–∂–µ –µ—Å—Ç—å –≤ —Å–ª–æ–≤–∞—Ä–µ
                                    _store_promo(row, columns, data_dict)
                                else:
                                    # –î–ª—è –æ–±—ã—á–Ω—ã—Ö —Ü–µ–Ω –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π —Ç–æ–≤–∞—Ä
                                    _store_row(row, columns, data_dict)
                            processed_goods += len(rows)
                    
                    # –ü—Ä–æ–≥—Ä–µ—Å—Å –≤–Ω—É—Ç—Ä–∏ –≥—Ä—É–ø–ø—ã
                    if pages_count > 5 and page % 5 == 0:
                        st.write(f"‚ÄÉ‚ÄÉüìÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {page + 1}/{pages_count} —Å—Ç—Ä–∞–Ω–∏—Ü")
                    
                    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
                    if page < pages_count - 1:
                        time.sleep(0.3)
                        
                except TimeoutException:
                    st.error(f"‚ÄÉ‚ÄÉ‚è∞ –¢–∞–π–º–∞—É—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ.")
                    break
                except Exception as e:
                    st.warning(f"‚ÄÉ‚ÄÉ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {e}")
                    continue
                    
            return processed_goods
            
        except TimeoutException:
            st.error(f"‚ÄÉ‚ÄÉ‚ùå –¢–∞–π–º–∞—É—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {group_name}")
            return 0
        except Exception as e:
            st.error(f"‚ÄÉ‚ÄÉ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {group_name}: {e}")
            return 0
    
    try:
        st.write(f"‚ÄÉüîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥—Ä—É–ø–ø—ã: {gname}")
        start_time = time.time()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–±—ã—á–Ω—ã–µ —Ü–µ–Ω—ã (–í–°–ï —Ç–æ–≤–∞—Ä—ã)
        regular_count = process_single_group(gid, f"{gname} (–æ–±—ã—á–Ω—ã–µ)", is_promo=False)
        
        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–∏–ø–∞–º–∏ —Ü–µ–Ω
        time.sleep(0.5)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–æ–º–æ-—Ü–µ–Ω—ã (–¢–û–õ–¨–ö–û –¥–ª—è —Ç–æ–≤–∞—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –µ—Å—Ç—å –≤ —Å–ª–æ–≤–∞—Ä–µ)
        promo_count = process_single_group(gid, f"{gname} (–ø—Ä–æ–º–æ)", is_promo=True)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        st.write(f"‚ÄÉ‚úÖ –ì—Ä—É–ø–ø–∞ {gname} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞: {regular_count} –æ–±—ã—á–Ω—ã—Ö + {promo_count} –ø—Ä–æ–º–æ —Ç–æ–≤–∞—Ä–æ–≤ (–≤—Ä–µ–º—è: {processing_time:.1f}—Å)")
        return True
        
    except TimeoutException:
        st.error(f"‚ÄÉ‚è∞ –û–±—â–∏–π —Ç–∞–π–º–∞—É—Ç –≥—Ä—É–ø–ø—ã {gname}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
        return False
    except Exception as e:
        st.error(f"‚ÄÉ‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≥—Ä—É–ø–ø—ã {gname}: {e}")
        return False

def skip_problematic_groups(main_group):
    """–ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –≥—Ä—É–ø–ø—ã"""
    # 3507 - –ø—Ä–æ–±–ª–µ–º–Ω–∞—è –≥—Ä—É–ø–ø–∞ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –æ—à–∏–±–æ–∫
    # 3516 - –•–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã (–ø–æ—Å–ª–µ–¥–Ω—è—è –∑–∞–≤–∏—Å—à–∞—è –≥—Ä—É–ø–ø–∞)
    skipped_ids = ['3507', '3516']
    
    filtered_groups = {}
    skipped_count = 0
    
    for name, (gid, children) in main_group.items():
        filtered_children = []
        for child in children:
            if str(child['GoodsGroupId']) in skipped_ids:
                skipped_count += 1
                st.warning(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—É—é –≥—Ä—É–ø–ø—É: {child.get('GoodsGroupName', 'Unknown')} (ID: {child['GoodsGroupId']})")
                continue
            filtered_children.append(child)
        
        if filtered_children:
            filtered_groups[name] = [gid, filtered_children]
    
    if skipped_count > 0:
        st.info(f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–ø—É—â–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –≥—Ä—É–ø–ø: {skipped_count}")
    
    return filtered_groups

def st_progress(iterable, *, desc=None, total=None):
    """–ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è Streamlit"""
    if total is None:
        total = len(iterable) if hasattr(iterable, "__len__") else 100

    bar = st.progress(0)
    if desc:
        st.text(desc)

    for i, item in enumerate(iterable):
        yield item
        bar.progress((i + 1) / total)

def post_merge(src_file: Path | str) -> Path:
    """–ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
    src_file = Path(src_file)
    const_file = Path("excel/ready_bc_main.xlsx")

    if not src_file.exists():
        st.error(f"–ù–µ –Ω–∞–π–¥–µ–Ω –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª: {src_file}")
        return src_file

    if not const_file.exists():
        st.error(f"–ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª-–∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞: {const_file}")
        return src_file

    df_main = pd.read_excel(src_file)
    df_bc = pd.read_excel(const_file)

    df = pd.merge(df_main, df_bc, how="left", on="name")
    if 'Unnamed: 0' in df.columns:
        df = df.drop(columns=['Unnamed: 0'])
    ts = datetime.datetime.now().strftime("%d%m%Y_%H%M")
    out_file = src_file.with_name(f"full{ts}.xlsx")
    df.to_excel(out_file, index=False)  # –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ index=False

    st.success(f"Post-merge –∑–∞–≤–µ—Ä—à—ë–Ω: {out_file.name}")
    return out_file

def build_api_report(file_path: str):
    """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    file_path = Path(file_path)
    
    st.header("üìä –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å API InfoPrice")
    st.write("‚è∞ –ü—Ä–æ—Ü–µ—Å—Å –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ API
    with st.spinner("–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ API..."):
        try:
            test_response = requests.get('https://api.infoprice.by', timeout=10)
            if test_response.status_code == 200:
                st.success("‚úÖ API –¥–æ—Å—Ç—É–ø–µ–Ω")
            else:
                st.warning(f"‚ö†Ô∏è API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å: {test_response.status_code}")
        except:
            st.error("‚ùå API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É.")
            return

    # –ü–æ–ª—É—á–∞–µ–º –≥—Ä—É–ø–ø—ã
    with st.spinner("–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π..."):
        main_group = get_main_group()
    
    if not main_group:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ –≥—Ä—É–ø–ø–∞—Ö —Ç–æ–≤–∞—Ä–æ–≤")
        return

    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –≥—Ä—É–ø–ø—ã
    main_group = skip_problematic_groups(main_group)
    
    if not main_group:
        st.error("–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –≥—Ä—É–ø–ø –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return

    columns = [
        "good_id", "category", "subcategory", "name", "link",
        "sosedi", "sosedi_promo", "korona", "korona_promo", "gippo", "gippo_promo",
        "evroopt", "evroopt_promo", "santa", "santa_promo", "green", "green_promo",
    ]
    data_dict = {}

    total_main = len(main_group)
    successful_groups = 0
    failed_groups = 0
    total_groups = sum(len(children) for _, children in main_group.values())

    # –≠–ª–µ–º–µ–Ω—Ç—ã –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    progress_bar = st.progress(0)
    status_text = st.empty()
    stats_text = st.empty()

    st.subheader("üìã –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π:")
    
    current_group = 0
    for i, main_name in enumerate(main_group.keys()):
        with st.expander(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è {i+1}/{total_main}: {main_name}", expanded=False):
            children = main_group[main_name][1]
            
            for j, group in enumerate(children):
                current_group += 1
                gid = group["GoodsGroupId"]
                gname = group.get("GoodsGroupName", f"–ì—Ä—É–ø–ø–∞ {gid}")
                
                # –ü—Ä–æ–≥—Ä–µ—Å—Å
                progress = current_group / total_groups
                progress_bar.progress(progress)
                status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∫–∞: {gname} ({current_group}/{total_groups})")
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥—Ä—É–ø–ø—ã
                try:
                    success = safe_process_group(gid, gname, main_name, data_dict, columns)
                except Exception as e:
                    st.error(f"‚ÄÉ‚ùå –ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
                    success = False
                
                if success:
                    successful_groups += 1
                else:
                    failed_groups += 1
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                stats_text.text(f"""
                üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:
                ‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö –≥—Ä—É–ø–ø: {successful_groups}
                ‚ùå –û—à–∏–±–æ–∫: {failed_groups}  
                üì¶ –¢–æ–≤–∞—Ä–æ–≤ —Å–æ–±—Ä–∞–Ω–æ: {len(data_dict):,}
                ‚è≥ –ü—Ä–æ–≥—Ä–µ—Å—Å: {current_group}/{total_groups} ({progress:.1%})
                """)
                
                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
                time.sleep(0.1)

    # –£–±–∏—Ä–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    progress_bar.empty()
    status_text.empty()
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if data_dict:
        st.subheader("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        try:
            df = pd.DataFrame(data_dict.values(), columns=columns)
            with pd.ExcelWriter(file_path, engine="openpyxl") as writer:
                df.to_excel(writer, sheet_name="AllData", index=False)
            
            st.success(f"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {file_path.name}")
            st.info(f"""
            **–ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**
            - –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(data_dict):,}
            - –£—Å–ø–µ—à–Ω—ã—Ö –≥—Ä—É–ø–ø: {successful_groups}
            - –ì—Ä—É–ø–ø —Å –æ—à–∏–±–∫–∞–º–∏: {failed_groups}
            - –í—Å–µ–≥–æ –≥—Ä—É–ø–ø: {total_groups}
            - –ü—Ä–æ–≥—Ä–µ—Å—Å: {current_group}/{total_groups} –≥—Ä—É–ø–ø –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ
            """)
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞
            st.subheader("üîß –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞...")
            with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
                try:
                    final_file = post_merge(file_path)
                    st.success(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –≥–æ—Ç–æ–≤!")
                    
                    # –°—Å—ã–ª–∫–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                    with open(final_file, "rb") as file:
                        file_data = file.read()
                    
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª",
                        data=file_data,
                        file_name=final_file.name,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        type="primary"
                    )
                    
                    st.info(f"**–§–∞–π–ª:** {final_file.name}")
                    
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
                    
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
    else:
        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ.")

def safe_build_api_report(file_path: str):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞"""
    try:
        build_api_report(file_path)
    except KeyboardInterrupt:
        st.warning("‚ö†Ô∏è –ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        st.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")